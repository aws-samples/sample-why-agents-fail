{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Tool Selection: Token Efficiency & Accuracy Analysis\n",
    "\n",
    "Based on: [Internal Representations as Indicators of Hallucinations in Agent Tool Selection](https://arxiv.org/pdf/2601.05214)\n",
    "\n",
    "## What This Demo Measures\n",
    "\n",
    "This notebook compares **Traditional** (all 31 tools) vs **Semantic** (top-3 filtered tools) approaches across two critical metrics:\n",
    "\n",
    "1. **Token Consumption**: How many tokens are used per query?\n",
    "2. **Tool Selection Accuracy**: Does the agent pick the correct tool?\n",
    "\n",
    "### The Dual Problem\n",
    "\n",
    "- ‚ùå **Token Waste**: Sending 31 tool descriptions = ~4,500 tokens per query\n",
    "- ‚ùå **Hallucination Risk**: More tools = more confusion = wrong tool selection\n",
    "\n",
    "### The Solution\n",
    "\n",
    "```\n",
    "User Query ‚Üí FAISS Search ‚Üí Top 3 Tools ‚Üí Agent ‚Üí Correct Selection + Fewer Tokens\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment to set manually:\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "\n",
    "assert os.getenv('OPENAI_API_KEY'), 'Set OPENAI_API_KEY in .env file or uncomment line above'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 29 tools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models.openai import OpenAIModel\n",
    "from enhanced_tools import ALL_TOOLS\n",
    "from registry import build_index, search_tools, swap_tools\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(ALL_TOOLS)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Semantic Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb6e576b7cd422baf108c0e62e6f168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexed 29 tools\n",
      "‚úÖ FAISS index built\n"
     ]
    }
   ],
   "source": [
    "build_index(ALL_TOOLS)\n",
    "print(\"‚úÖ FAISS index built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries\n",
    "\n",
    "Diverse queries testing different tool categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Test suite: 13 queries\n",
      "üìä Tool pool: 29 tools\n"
     ]
    }
   ],
   "source": [
    "TESTS = [\n",
    "    # Ambiguous queries - could match multiple tools\n",
    "    (\"Search for something in Paris\", \"search\"),  # Generic vs search_hotels\n",
    "    (\"Check something\", \"check\"),  # Generic vs check_hotel_availability\n",
    "    (\"Get some details\", \"get_details\"),  # Generic vs get_hotel_details\n",
    "    (\"What's the status?\", \"get_status\"),  # Generic vs get_flight_status\n",
    "    (\"I need information\", \"get_info\"),  # Generic vs specific tools\n",
    "    \n",
    "    # Hotel queries - similar tools\n",
    "    (\"Search hotels in Barcelona\", \"search_hotels\"),  # vs search_real_hotels\n",
    "    (\"Find real hotels in France\", \"search_real_hotels\"),  # vs search_hotels\n",
    "    (\"How much does a hotel cost?\", \"get_hotel_pricing\"),  # vs get_hotel_details\n",
    "    (\"What amenities does the hotel have?\", \"get_hotel_details\"),  # vs get_hotel_pricing\n",
    "    (\"Is the hotel available tomorrow?\", \"check_hotel_availability\"),  # vs check_hotel_availability_dates\n",
    "    (\"Check availability from March 15 to 18\", \"check_hotel_availability_dates\"),  # vs check_hotel_availability\n",
    "    \n",
    "    # Flight queries - similar tools\n",
    "    (\"Find flights to Tokyo\", \"search_flights\"),  # vs search_flight_prices\n",
    "    (\"How much do flights cost?\", \"search_flight_prices\"),  # vs search_flights\n",
    "    (\"Is flight AA123 on time?\", \"get_flight_status\"),  # vs get_flight_details\n",
    "    \n",
    "    # Booking queries - generic vs specific\n",
    "    (\"Book a hotel for me\", \"book_hotel\"),  # vs book (generic)\n",
    "    (\"Book a flight for me\", \"book_flight\"),  # vs book (generic)\n",
    "    (\"Book something\", \"book\"),  # Generic\n",
    "    \n",
    "    # Clear specific queries\n",
    "    (\"Convert 500 USD to EUR\", \"get_currency_exchange\"),\n",
    "    (\"Do I need a visa for Spain?\", \"get_travel_documents\"),\n",
    "]\n",
    "\n",
    "print(f\"üìã Test suite: {len(TESTS)} queries (ambiguous queries to test tool confusion)\")\n",
    "print(f\"üìä Tool pool: {len(ALL_TOOLS)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_capture_with_tokens(agent, query: str) -> Tuple[List[str], Dict]:\n",
    "    \"\"\"Run agent and capture tool calls + token usage\"\"\"\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "    \n",
    "    try:\n",
    "        result = agent(query)\n",
    "        output = sys.stdout.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "    \n",
    "    # Extract tool calls\n",
    "    tools = re.findall(r'Tool #\\d+: (\\w+)', output)\n",
    "    \n",
    "    # Extract token usage from result\n",
    "    tokens = {'input': 0, 'output': 0, 'total': 0}\n",
    "    \n",
    "    if hasattr(result, 'metrics'):\n",
    "        summary = result.metrics.get_summary()\n",
    "        usage = summary.get('accumulated_usage', {})\n",
    "        tokens['input'] = usage.get('inputTokens', 0)\n",
    "        tokens['output'] = usage.get('outputTokens', 0)\n",
    "        tokens['total'] = usage.get('totalTokens', 0)\n",
    "    \n",
    "    # Fallback: estimate if no usage data\n",
    "    if tokens['total'] == 0:\n",
    "        num_tools = len(agent.tool_registry.get_all_tools_config())\n",
    "        tokens['input'] = num_tools * 50 + 100  # ~50 tokens per tool + prompt\n",
    "        tokens['output'] = 50  # estimated\n",
    "        tokens['total'] = tokens['input'] + tokens['output']\n",
    "        tokens['estimated'] = True\n",
    "    \n",
    "    return tools, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Traditional Approach (All 29 Tools)\n",
    "\n",
    "Agent receives all tools on every query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: TRADITIONAL - 29 tools every query\n",
      "================================================================================\n",
      "‚úÖ What's the current weather in Paris?               |  1806 tokens\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Is it raining in Tokyo right now?                  |  1815 tokens\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Find me flights from New York to London next week  |  1855 tokens\n",
      "   Called: ['search_flights']\n",
      "‚úÖ What's the status of flight AA123?                 |  1821 tokens\n",
      "   Called: ['get_flight_status']\n",
      "‚ùå How much do flights to Tokyo cost?                 |   900 tokens\n",
      "   Called: NO TOOL\n",
      "‚ùå Book a hotel room in Rome for John Smith           |   935 tokens\n",
      "   Called: NO TOOL\n",
      "‚úÖ Search for hotels in Barcelona                     |  1822 tokens\n",
      "   Called: ['search_hotels']\n",
      "‚úÖ How much does a room at the Marriott cost?         |  1827 tokens\n",
      "   Called: ['get_hotel_pricing']\n",
      "‚ùå Show me the top-rated hotels in the database       |  1835 tokens\n",
      "   Called: ['search_hotels']\n",
      "‚ùå Find hotels in France with rating above 9.0        |  2915 tokens\n",
      "   Called: ['search_hotels', 'search_hotel_reviews']\n",
      "‚ùå Cancel my reservation                              |   899 tokens\n",
      "   Called: NO TOOL\n",
      "‚úÖ Convert 500 USD to EUR                             |  1844 tokens\n",
      "   Called: ['get_currency_exchange']\n",
      "‚úÖ Do I need a visa to travel to Spain from USA?      |  1869 tokens\n",
      "   Called: ['get_travel_documents']\n",
      "\n",
      "üìä Traditional Results:\n",
      "   Accuracy: 8/13 (61.5%)\n",
      "   Total tokens: 22,143\n",
      "   Avg tokens/query: 1703\n"
     ]
    }
   ],
   "source": [
    "MODEL = OpenAIModel(model_id=\"gpt-4o-mini\")\n",
    "PROMPT = \"You are a travel assistant. Use the correct tool to answer questions.\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"TEST 1: TRADITIONAL - {len(ALL_TOOLS)} tools every query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trad_results = []\n",
    "trad_correct = 0\n",
    "trad_total_tokens = 0\n",
    "\n",
    "for query, expected in TESTS:\n",
    "    agent = Agent(tools=ALL_TOOLS, system_prompt=PROMPT, model=MODEL)\n",
    "    tools, tokens = run_and_capture_with_tokens(agent, query)\n",
    "    \n",
    "    ok = expected in tools\n",
    "    trad_correct += ok\n",
    "    trad_total_tokens += tokens['total']\n",
    "    \n",
    "    trad_results.append({\n",
    "        'query': query,\n",
    "        'expected': expected,\n",
    "        'actual': tools,\n",
    "        'correct': ok,\n",
    "        'tokens': tokens\n",
    "    })\n",
    "    \n",
    "    status = '‚úÖ' if ok else '‚ùå'\n",
    "    est = ' (est)' if tokens.get('estimated') else ''\n",
    "    print(f\"{status} {query[:50]:50} | {tokens['total']:5} tokens{est}\")\n",
    "    print(f\"   Called: {tools[:2] if tools else 'NO TOOL'}\")\n",
    "\n",
    "print(f\"\\nüìä Traditional Results:\")\n",
    "print(f\"   Accuracy: {trad_correct}/{len(TESTS)} ({100*trad_correct/len(TESTS):.1f}%)\")\n",
    "print(f\"   Total tokens: {trad_total_tokens:,}\")\n",
    "print(f\"   Avg tokens/query: {trad_total_tokens/len(TESTS):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Semantic Approach (Top-3 Filtered Tools)\n",
    "\n",
    "Agent receives only the 3 most relevant tools per query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: SEMANTIC - Top-3 tools per query\n",
      "================================================================================\n",
      "‚úÖ What's the current weather in Paris?               |   284 tokens\n",
      "   Available: ['get_weather', 'get_weather_forecast', 'get_weather_alerts']\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Is it raining in Tokyo right now?                  |   295 tokens\n",
      "   Available: ['get_weather_alerts', 'get_weather', 'get_weather_forecast']\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Find me flights from New York to London next week  |   374 tokens\n",
      "   Available: ['search_flight_prices', 'search_flights', 'get_flight_details']\n",
      "   Called: ['search_flights']\n",
      "‚úÖ What's the status of flight AA123?                 |   321 tokens\n",
      "   Available: ['get_flight_status', 'check_flight_availability', 'get_flight_details']\n",
      "   Called: ['get_flight_status']\n",
      "‚ùå How much do flights to Tokyo cost?                 |   161 tokens\n",
      "   Available: ['search_flight_prices', 'search_flights', 'book_flight']\n",
      "   Called: NO TOOL\n",
      "‚ùå Book a hotel room in Rome for John Smith           |   164 tokens\n",
      "   Available: ['book_hotel', 'get_hotel_pricing', 'check_hotel_availability']\n",
      "   Called: NO TOOL\n",
      "‚úÖ Search for hotels in Barcelona                     |   317 tokens\n",
      "   Available: ['search_hotels', 'search_hotel_reviews', 'get_hotel_details']\n",
      "   Called: ['search_hotels']\n",
      "‚úÖ How much does a room at the Marriott cost?         |   339 tokens\n",
      "   Available: ['get_hotel_pricing', 'get_hotel_details', 'book_hotel']\n",
      "   Called: ['get_hotel_pricing']\n",
      "‚ùå Show me the top-rated hotels in the database       |   347 tokens\n",
      "   Available: ['search_hotel_reviews', 'get_hotel_details', 'search_hotels']\n",
      "   Called: ['search_hotels']\n",
      "‚ùå Find hotels in France with rating above 9.0        |   652 tokens\n",
      "   Available: ['search_hotel_reviews', 'search_hotels', 'get_hotel_details']\n",
      "   Called: ['search_hotels', 'get_hotel_details']\n",
      "‚ùå Cancel my reservation                              |   141 tokens\n",
      "   Available: ['cancel', 'refund_payment', 'check_flight_availability']\n",
      "   Called: NO TOOL\n",
      "‚úÖ Convert 500 USD to EUR                             |   426 tokens\n",
      "   Available: ['get_currency_exchange', 'get_hotel_pricing', 'compare_hotel_prices']\n",
      "   Called: ['get_currency_exchange']\n",
      "‚úÖ Do I need a visa to travel to Spain from USA?      |   414 tokens\n",
      "   Available: ['get_travel_documents', 'get_currency_exchange', 'get_flight_status']\n",
      "   Called: ['get_travel_documents']\n",
      "\n",
      "üìä Semantic Results:\n",
      "   Accuracy: 8/13 (61.5%)\n",
      "   Total tokens: 4,235\n",
      "   Avg tokens/query: 326\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 2: SEMANTIC - Top-3 tools per query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sem_results = []\n",
    "sem_correct = 0\n",
    "sem_total_tokens = 0\n",
    "\n",
    "for query, expected in TESTS:\n",
    "    selected = search_tools(query, top_k=3)\n",
    "    selected_names = [t.__name__ for t in selected]\n",
    "    \n",
    "    agent = Agent(tools=selected, system_prompt=PROMPT, model=MODEL)\n",
    "    tools, tokens = run_and_capture_with_tokens(agent, query)\n",
    "    \n",
    "    ok = expected in tools\n",
    "    sem_correct += ok\n",
    "    sem_total_tokens += tokens['total']\n",
    "    \n",
    "    sem_results.append({\n",
    "        'query': query,\n",
    "        'expected': expected,\n",
    "        'selected': selected_names,\n",
    "        'actual': tools,\n",
    "        'correct': ok,\n",
    "        'tokens': tokens\n",
    "    })\n",
    "    \n",
    "    status = '‚úÖ' if ok else '‚ùå'\n",
    "    est = ' (est)' if tokens.get('estimated') else ''\n",
    "    print(f\"{status} {query[:50]:50} | {tokens['total']:5} tokens{est}\")\n",
    "    print(f\"   Available: {selected_names}\")\n",
    "    print(f\"   Called: {tools[:2] if tools else 'NO TOOL'}\")\n",
    "\n",
    "print(f\"\\nüìä Semantic Results:\")\n",
    "print(f\"   Accuracy: {sem_correct}/{len(TESTS)} ({100*sem_correct/len(TESTS):.1f}%)\")\n",
    "print(f\"   Total tokens: {sem_total_tokens:,}\")\n",
    "print(f\"   Avg tokens/query: {sem_total_tokens/len(TESTS):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Semantic + Memory (Single Agent)\n",
    "\n",
    "Same agent across all queries, tools swapped dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 3: SEMANTIC + MEMORY - Single agent, dynamic tool swapping\n",
      "================================================================================\n",
      "‚úÖ What's the current weather in Paris?               |   284 tokens\n",
      "   Available: ['get_weather', 'get_weather_forecast', 'get_weather_alerts'] | Memory: 4 msgs\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Is it raining in Tokyo right now?                  |   688 tokens\n",
      "   Available: ['get_weather_alerts', 'get_weather', 'get_weather_forecast'] | Memory: 8 msgs\n",
      "   Called: ['get_weather']\n",
      "‚úÖ Find me flights from New York to London next week  |  1294 tokens\n",
      "   Available: ['search_flight_prices', 'search_flights', 'get_flight_details'] | Memory: 12 msgs\n",
      "   Called: ['search_flights']\n",
      "‚úÖ What's the status of flight AA123?                 |  2036 tokens\n",
      "   Available: ['get_flight_status', 'check_flight_availability', 'get_flight_details'] | Memory: 16 msgs\n",
      "   Called: ['get_flight_status']\n",
      "‚úÖ How much do flights to Tokyo cost?                 |  2967 tokens\n",
      "   Available: ['search_flight_prices', 'search_flights', 'book_flight'] | Memory: 20 msgs\n",
      "   Called: ['search_flight_prices']\n",
      "‚úÖ Book a hotel room in Rome for John Smith           |  4050 tokens\n",
      "   Available: ['book_hotel', 'get_hotel_pricing', 'check_hotel_availability'] | Memory: 24 msgs\n",
      "   Called: ['book_hotel']\n",
      "‚úÖ Search for hotels in Barcelona                     |  5218 tokens\n",
      "   Available: ['search_hotels', 'search_hotel_reviews', 'get_hotel_details'] | Memory: 28 msgs\n",
      "   Called: ['search_hotels']\n",
      "‚úÖ How much does a room at the Marriott cost?         |  6551 tokens\n",
      "   Available: ['get_hotel_pricing', 'get_hotel_details', 'book_hotel'] | Memory: 32 msgs\n",
      "   Called: ['get_hotel_pricing']\n",
      "‚ùå Show me the top-rated hotels in the database       |  8021 tokens\n",
      "   Available: ['search_hotel_reviews', 'get_hotel_details', 'search_hotels'] | Memory: 36 msgs\n",
      "   Called: ['search_hotels']\n",
      "‚ùå Find hotels in France with rating above 9.0        |  9639 tokens\n",
      "   Available: ['search_hotel_reviews', 'search_hotels', 'get_hotel_details'] | Memory: 40 msgs\n",
      "   Called: ['search_hotels']\n",
      "‚úÖ Cancel my reservation                              | 11360 tokens\n",
      "   Available: ['cancel', 'refund_payment', 'check_flight_availability'] | Memory: 44 msgs\n",
      "   Called: ['cancel']\n",
      "‚úÖ Convert 500 USD to EUR                             | 13340 tokens\n",
      "   Available: ['get_currency_exchange', 'get_hotel_pricing', 'compare_hotel_prices'] | Memory: 48 msgs\n",
      "   Called: ['get_currency_exchange']\n",
      "‚úÖ Do I need a visa to travel to Spain from USA?      | 15458 tokens\n",
      "   Available: ['get_travel_documents', 'get_currency_exchange', 'get_flight_status'] | Memory: 52 msgs\n",
      "   Called: ['get_travel_documents']\n",
      "\n",
      "üìä Semantic+Memory Results:\n",
      "   Accuracy: 11/13 (84.6%)\n",
      "   Total tokens: 80,906\n",
      "   Avg tokens/query: 6224\n",
      "   Final conversation: 52 messages\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 3: SEMANTIC + MEMORY - Single agent, dynamic tool swapping\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "initial_tools = search_tools(TESTS[0][0], top_k=3)\n",
    "memory_agent = Agent(tools=initial_tools, system_prompt=PROMPT, model=MODEL)\n",
    "\n",
    "mem_results = []\n",
    "mem_correct = 0\n",
    "mem_total_tokens = 0\n",
    "\n",
    "for query, expected in TESTS:\n",
    "    selected = search_tools(query, top_k=3)\n",
    "    selected_names = [t.__name__ for t in selected]\n",
    "    swap_tools(memory_agent, selected)\n",
    "    \n",
    "    tools, tokens = run_and_capture_with_tokens(memory_agent, query)\n",
    "    \n",
    "    ok = expected in tools\n",
    "    mem_correct += ok\n",
    "    mem_total_tokens += tokens['total']\n",
    "    \n",
    "    mem_results.append({\n",
    "        'query': query,\n",
    "        'expected': expected,\n",
    "        'selected': selected_names,\n",
    "        'actual': tools,\n",
    "        'correct': ok,\n",
    "        'tokens': tokens,\n",
    "        'messages': len(memory_agent.messages)\n",
    "    })\n",
    "    \n",
    "    status = '‚úÖ' if ok else '‚ùå'\n",
    "    est = ' (est)' if tokens.get('estimated') else ''\n",
    "    print(f\"{status} {query[:50]:50} | {tokens['total']:5} tokens{est}\")\n",
    "    print(f\"   Available: {selected_names} | Memory: {len(memory_agent.messages)} msgs\")\n",
    "    print(f\"   Called: {tools[:2] if tools else 'NO TOOL'}\")\n",
    "\n",
    "print(f\"\\nüìä Semantic+Memory Results:\")\n",
    "print(f\"   Accuracy: {mem_correct}/{len(TESTS)} ({100*mem_correct/len(TESTS):.1f}%)\")\n",
    "print(f\"   Total tokens: {mem_total_tokens:,}\")\n",
    "print(f\"   Avg tokens/query: {mem_total_tokens/len(TESTS):.0f}\")\n",
    "print(f\"   Final conversation: {len(memory_agent.messages)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Accuracy Comparison:\")\n",
    "print(f\"   Traditional:      {trad_correct}/{len(TESTS)} ({100*trad_correct/len(TESTS):.1f}%)\")\n",
    "print(f\"   Semantic:         {sem_correct}/{len(TESTS)} ({100*sem_correct/len(TESTS):.1f}%)\")\n",
    "print(f\"   Semantic+Memory:  {mem_correct}/{len(TESTS)} ({100*mem_correct/len(TESTS):.1f}%)\")\n",
    "\n",
    "if sem_correct > trad_correct:\n",
    "    print(f\"   ‚úÖ Semantic improved by +{sem_correct - trad_correct} queries\")\n",
    "elif sem_correct < trad_correct:\n",
    "    print(f\"   ‚ö†Ô∏è  Semantic decreased by {trad_correct - sem_correct} queries\")\n",
    "else:\n",
    "    print(f\"   ‚û°Ô∏è  Same accuracy\")\n",
    "\n",
    "print(f\"\\nüí∞ Token Consumption:\")\n",
    "print(f\"   Traditional:      {trad_total_tokens:,} tokens ({trad_total_tokens/len(TESTS):.0f} avg)\")\n",
    "print(f\"   Semantic:         {sem_total_tokens:,} tokens ({sem_total_tokens/len(TESTS):.0f} avg)\")\n",
    "print(f\"   Semantic+Memory:  {mem_total_tokens:,} tokens ({mem_total_tokens/len(TESTS):.0f} avg)\")\n",
    "\n",
    "if trad_total_tokens > 0:\n",
    "    sem_savings = trad_total_tokens - sem_total_tokens\n",
    "    mem_savings = trad_total_tokens - mem_total_tokens\n",
    "    print(f\"\\nüí° Token Savings:\")\n",
    "    print(f\"   Semantic vs Traditional:  {sem_savings:,} tokens ({100*sem_savings/trad_total_tokens:.1f}% reduction)\")\n",
    "    print(f\"   Memory vs Traditional:    {mem_savings:,} tokens ({100*mem_savings/trad_total_tokens:.1f}% reduction)\")\n",
    "    \n",
    "    if mem_total_tokens > sem_total_tokens:\n",
    "        overhead = mem_total_tokens - sem_total_tokens\n",
    "        print(f\"   Memory overhead:          +{overhead:,} tokens (conversation history)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Query Token Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PER-QUERY TOKEN BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Query':<50} {'Trad':>8} {'Sem':>8} {'Mem':>8} {'Saved':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i in range(len(TESTS)):\n",
    "    query = TESTS[i][0][:49]\n",
    "    trad_tok = trad_results[i]['tokens']['total']\n",
    "    sem_tok = sem_results[i]['tokens']['total']\n",
    "    mem_tok = mem_results[i]['tokens']['total']\n",
    "    saved = trad_tok - sem_tok\n",
    "    \n",
    "    print(f\"{query:<50} {trad_tok:8} {sem_tok:8} {mem_tok:8} {saved:8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüîç Traditional Errors:\")\n",
    "trad_errors = [r for r in trad_results if not r['correct']]\n",
    "if trad_errors:\n",
    "    for r in trad_errors:\n",
    "        print(f\"   ‚ùå '{r['query'][:60]}'\")\n",
    "        print(f\"      Expected: {r['expected']}, Got: {r['actual']}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No errors\")\n",
    "\n",
    "print(f\"\\nüîç Semantic Errors:\")\n",
    "sem_errors = [r for r in sem_results if not r['correct']]\n",
    "if sem_errors:\n",
    "    for r in sem_errors:\n",
    "        print(f\"   ‚ùå '{r['query'][:60]}'\")\n",
    "        print(f\"      Expected: {r['expected']}, Got: {r['actual']}\")\n",
    "        print(f\"      Available: {r['selected']}\")\n",
    "        if r['expected'] not in r['selected']:\n",
    "            print(f\"      ‚ö†Ô∏è  Correct tool NOT in top-3 (FAISS filtering issue)\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No errors\")\n",
    "\n",
    "print(f\"\\nüîç Semantic+Memory Errors:\")\n",
    "mem_errors = [r for r in mem_results if not r['correct']]\n",
    "if mem_errors:\n",
    "    for r in mem_errors:\n",
    "        print(f\"   ‚ùå '{r['query'][:60]}'\")\n",
    "        print(f\"      Expected: {r['expected']}, Got: {r['actual']}\")\n",
    "        print(f\"      Available: {r['selected']}\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "| Approach | Tools/Query | Accuracy | Avg Tokens | Token Savings |\n",
    "|----------|-------------|----------|------------|---------------|\n",
    "| Traditional | 31 tools | X% | ~Y tokens | Baseline |\n",
    "| Semantic | 3 tools | X% | ~Y tokens | Z% |\n",
    "| Semantic+Memory | 3 tools | X% | ~Y tokens | Z% |\n",
    "\n",
    "### Why Semantic Tool Selection Works\n",
    "\n",
    "1. **Reduced Token Waste**: 3 tools vs 31 = ~89% fewer tokens on tool descriptions\n",
    "2. **Better Accuracy**: Fewer choices = less confusion = correct tool selection\n",
    "3. **Production Ready**: `swap_tools()` preserves conversation memory\n",
    "\n",
    "### References\n",
    "\n",
    "- [Internal Representations as Indicators of Hallucinations in Agent Tool Selection](https://arxiv.org/pdf/2601.05214)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
