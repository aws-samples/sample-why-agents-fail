# ğŸ¤– Why AI Agents Fail (And How to Fix Them)

[![GitHub stars](https://img.shields.io/github/stars/build-on-aws/why-agents-fail.svg?style=for-the-badge&logo=github&color=yellow)](https://github.com/build-on-aws/why-agents-fail/stargazers) [![License](https://img.shields.io/badge/License-MIT--0-blue.svg?style=for-the-badge)](LICENSE) [![Python](https://img.shields.io/badge/Python-3.9+-green.svg?style=for-the-badge&logo=python)](https://python.org) [![AWS](https://img.shields.io/badge/AWS-Bedrock-orange.svg?style=for-the-badge&logo=amazon-aws)](https://aws.amazon.com/bedrock/) [![Strands](https://img.shields.io/badge/ğŸ§¬-Strands_Agents-blue.svg?style=for-the-badge)](https://strandsagents.com)

*Research-backed solutions to the three critical failure modes that break AI agents in production: hallucinations, timeouts, and memory loss.*

â­ Star this repository

---

## ğŸ¯ Learning Path: Understand â†’ Prevent â†’ Scale

AI agents fail in three predictable ways. This repository demonstrates research-backed techniques to prevent each failure mode with working code examples.

| ğŸš¨ Failure Mode | ğŸ’¡ Solution Approach | ğŸ“Š Projects | â±ï¸ Total Time |
|----------------|---------------------|-------------|---------------|
| **[ğŸ­ Hallucinations](#-stop-ai-agent-hallucinations)** | Detection and mitigation through 4 techniques | 4 demos | 2 hours |
| **â±ï¸ Timeouts** | Context management and async patterns | Coming soon | - |
| **ğŸ§  Memory Loss** | Persistent memory and context retrieval | Coming soon | - |

---

## ğŸ­ Stop AI Agent Hallucinations

**The Problem**: Agents fabricate statistics, choose wrong tools, ignore business rules, and claim success when operations fail.

**The Solution**: 4 research-backed techniques that detect, contain, and mitigate hallucinations before they cause damage.

### ğŸ““ Hallucination Prevention Demos

| ğŸ““ Demo | ğŸ¯ Focus & Key Learning | â±ï¸ Time | ğŸ“Š Level |
|---------|------------------------|----------|----------|
| **01 - [Graph-RAG vs Traditional RAG](stop-ai-agent-hallucinations/01-faq-graphrag-demo/)** | Structured data retrieval - Compare RAG vs Graph-RAG on 300 hotel FAQs, Neo4j knowledge graph with auto entity extraction, eliminate statistical hallucinations | 30 min | ![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) |
| **02 - [Semantic Tool Selection with FAISS](stop-ai-agent-hallucinations/02-semantic-tools-demo/)** | Intelligent tool filtering - Filter 31 tools to top 3 relevant, reduce errors by 75% and token costs by 89%, dynamic tool swapping | 45 min | ![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) |
| **03 - [Multi-Agent Validation Pattern](stop-ai-agent-hallucinations/03-multiagent-demo/)** | Cross-validation workflows - Executor â†’ Validator â†’ Critic pattern catches hallucinations, Strands Swarm orchestration | 30 min | ![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) |
| **04 - [Neurosymbolic Rule Enforcement](stop-ai-agent-hallucinations/04-neurosymbolic-demo/)** | Symbolic validation - Compare prompt engineering vs symbolic rules, 100% business rule compliance, LLM cannot bypass | 20 min |![Intermediate](https://img.shields.io/badge/-Intermediate-yellow) |

### ğŸ“Š Key Results

| ğŸ¯ Technique | ğŸ“ˆ Improvement | ğŸ” Metric |
|--------------|----------------|-----------|
| **Graph-RAG** | 100% accuracy | Precise queries on 300 hotel FAQs via knowledge graph |
| **Semantic Tool Selection** | 86.4% detection | Tool selection hallucination detection (research validated) |
| **Semantic Tool Selection** | 89% token reduction | Token cost per query: 4,500 â†’ 500 tokens |
| **Neurosymbolic Rules** | 100% compliance | Business rule enforcement - LLM cannot bypass |
| **Multi-Agent Validation** | Detects errors | Invalid operation detection before reaching users |

**[â†’ Explore hallucination prevention demos](stop-ai-agent-hallucinations/)**

---

## â±ï¸ Why Your Agent Times Out

*(Coming soon)*

---

## ğŸ§  Your Agent Doesn't Remember You

*(Coming soon)*

---

## ğŸ”§ Technologies Used

<details>

| ğŸ”§ Technology | ğŸ¯ Purpose | âš¡ Key Capabilities |
|---------------|------------|---------------------|
| **[Strands Agents](https://strandsagents.com)** | AI agent framework | Dynamic tool swapping, multi-agent orchestration, conversation memory, hooks system |
| **[Amazon Bedrock](https://aws.amazon.com/bedrock/)** | LLM access | Claude 3 Haiku/Sonnet for agent reasoning and tool calling |
| **[Neo4j](https://neo4j.com)** | Graph database | Relationship-aware queries, precise aggregations, multi-hop traversal |
| **[FAISS](https://github.com/facebookresearch/faiss)** | Vector search | Semantic similarity, tool filtering, efficient nearest neighbor search |
| **[SentenceTransformers](https://www.sbert.net/)** | Embeddings | Text embeddings for semantic tool selection and memory retrieval |

</details>

---

## ğŸ¯ Prerequisites

**Before You Begin:**
- Python 3.9+ installed locally
- LLM access: OpenAI (default), AWS Bedrock, Anthropic, or Ollama
- `OPENAI_API_KEY` environment variable (for default setup)
- AWS CLI configured if using Bedrock (`aws configure`)
- Basic understanding of AI agents and tool calling

**Model Configuration:**
All demos use OpenAI with GPT-4o-mini by default. You can swap to any provider supported by Strands â€” see [Strands Model Providers](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/model-providers/) for configuration.

**AWS Credentials Setup (if using Bedrock):**
Follow the [AWS credentials configuration guide](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) to configure your environment.

---

## ğŸš€ Quick Start Guide

### 1. **Clone Repository**
```bash
git clone https://github.com/aws-samples/sample-why-agents-fail
cd why-agents-fail
```

### 2. **Start with Hallucinations**
```bash
cd stop-ai-agent-hallucinations
```

### 3. **Explore All Techniques**
Each demo folder contains detailed README files and working code examples.

---

## ğŸ“š Research Background

This repository implements techniques from recent research papers:

**Hallucinations:**
- [MetaRAG: Metamorphic Testing for Hallucination Detection](https://arxiv.org/pdf/2509.09360)
- [Internal Representations as Indicators of Hallucinations in Agent Tool Selection](https://arxiv.org/abs/2601.05214)
- [Teaming LLMs to Detect and Mitigate Hallucinations](https://arxiv.org/pdf/2510.19507)
- [RAG-KG-IL: Multi-Agent Hybrid Framework](https://arxiv.org/pdf/2503.13514)

**Timeouts & Memory:**
- Coming soon

---

## ğŸ’° Cost Estimation

| ğŸ’° Service | ğŸ’µ Approximate Cost | ğŸ“Š Usage Pattern | ğŸ”— Pricing Link |
|-------------|---------------------|------------------|------------------|
| OpenAI GPT-4o-mini | ~$0.15 per 1M input tokens | Agent reasoning and tool calling | [OpenAI Pricing](https://openai.com/pricing) |
| Amazon Bedrock (Claude) | ~$0.25 per 1M input tokens | Alternative LLM provider | [Bedrock Pricing](https://aws.amazon.com/bedrock/pricing/) |
| Neo4j (local) | Free | Graph database for demos | [Neo4j Community](https://neo4j.com/download/) |
| FAISS (local) | Free | Vector search library | Open source |
| SentenceTransformers | Free | Local embeddings | Open source |

> ğŸ’¡ All demos can run locally with minimal costs. OpenAI GPT-4o-mini is the most cost-effective option for testing.

---

## ğŸ“– Additional Learning Resources

- [Strands Agents Documentation](https://strandsagents.com) - Framework documentation and model providers
- [AWS Bedrock Documentation](https://docs.aws.amazon.com/bedrock/) - LLM service guide and model access
- [Neo4j Graph Database Guide](https://neo4j.com/docs/) - Graph database setup and Cypher queries

---

<div align="center">

**â­ Star this repository** â€¢ **ğŸ“– [Start Learning](stop-ai-agent-hallucinations/)**

</div>


---

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

---

## ğŸ“„ License

This library is licensed under the MIT-0 License. See the [LICENSE](LICENSE) file for details.


